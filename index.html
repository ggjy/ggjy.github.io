<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Jianyuan Guo's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Jianyuan Guo is currently a PhD student at School of Computer Science, University of Sydney.">
  <meta name="keywords" content="Jianyuan Guo, 郭健元, guojianyuan, Jianyuan, Guo, Deep Learning, PKU, Computer Vision, Machine Learning, Model Compression, Object Detection">
  <meta name="author" content="Jianyuan Guo" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.jpg">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Jianyuan</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#publications" class="w3-bar-item w3-button">Publications</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Jianyuan</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 200px" alt="profile photo" src="images/Jianyuan.JPG">
      <h1>Jianyuan Guo (郭健元)</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
        
          I am a 3rd-year PhD student in the School of Computer Science, <a href="https://www.sydney.edu.au/">The University of Sydney</a>. I am supervised by <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/c-xu.html"> Prof. Chang Xu</a>. I obtained the B.S. and M.S. from the school of EECS, <a href="https://www.pku.edu.cn/">Peking University</a> at 2017 and 2020, supervised by <a href="https://www.cis.pku.edu.cn/info/1084/1272.htm"> Prof. Chao Zhang</a>. My main research interest lies in machine perception algorithms and their related applications, including efficient neural network (e.g., CNN and Transformer) in computer vision and natural language processing, self-supervised learning, neural architecture search, multimodal fusion, and LLM for AGI.
          
        </p>
        <p class="w3-center">
          <a href="mailto:jianyuanguo12138@gmail.com">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&user=UnAbd4gAAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/ggjy">Github</a> &nbsp/&nbsp
          <a href="https://dblp.org/pid/190/0258.html"> DBLP </a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 05/2024, 2 papers are accepted by ICML 2024.</li></p>
      <p><li> 02/2024, Great honor to join the <a href="https://aaai.org/about-aaai/aaai-officers-and-committees/">AAAI Student Committee</a>.</li></p>
      <p><li> 02/2024, We release the code of <a href="https://github.com/ggjy/vision_weak_to_strong">Vision Superalignment</a> and <a href="https://github.com/ggjy/DeLVM">Data efficient Large Vision Modle (LVM)</a>.</li></p>  
      <p><li> 10/2023, 4 papers are accepted by NeurIPS 2023.</li></p>
      <p><li> 03/2022, 5 papers are accepted by CVPR 2022.</li></p>
      <p><li> 09/2022, 4 papers are accepted by NeurIPS 2022.</li></p>

 </div>
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32" id="publications">
    <h2>Selected Publications</h2>

    <p>
    <li><strong>Data-efficient Large Vision Models through Sequential Autoregression.</strong>
    <br>
    <strong>Jianyuan Guo*</strong>, Zhiwei Hao*, Chengcheng Wang*, Yehui Tang, Han Wu, Han Hu, Kai Han, Chang Xu
    <br>
    <em>ICML</em> 2024 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2402.04841">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/DeLVM">code</a>  
    </p>

    <p>
    <li><strong>Revisit the Power of Vanilla Knowledge Distillation from Small Scale to Large Scale.</strong>
    <br>
    Zhiwei Hao*, <strong>Jianyuan Guo*</strong>, Kai Han, Han Hu, Chang Xu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2023 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2305.15781.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/Hao840/vanillaKD">code</a>  
    </p>

    <p>
    <li><strong>One-for-All: Bridge the Gap Between Heterogeneous Architectures in Knowledge Distillation.</strong>
    <br>
    Zhiwei Hao, <strong>Jianyuan Guo</strong>, Kai Han, Yehui Tang, Han Hu, Yunhe Wang, Chang Xu
    <br>
    <em>NeurIPS</em> 2023 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2310.19444.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/Hao840/OFAKD">code</a>  
    </p>

    <p>
    <li><strong>VanillaNet: the Power of Minimalism in Deep Learning.</strong>
    <br>
    Hanting Chen, Yunhe Wang, <strong>Jianyuan Guo</strong>, Dacheng Tao
    <br>
    <em>NeurIPS</em> 2023 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2305.12972.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/huawei-noah/VanillaNet">code</a>  
    </p>

    <p>
    <li><strong>Hierarchical relational learning for few-shot knowledge graph completion.</strong>
    <br>
    Han Wu, Jie Yin, Bala Rajaratnam, <strong>Jianyuan Guo</strong>
    <br>
    <em>ICLR</em> 2023 | <a style="color: #447ec9" href="https://openreview.net/pdf?id=zlwBI2gQL3K">paper</a> |
    <a style="color: #447ec9" href="https://github.com/alexhw15/HiRe">code</a>  
    </p>
    
    <p>
    <li><strong>Hire-MLP: Vision MLP via Hierarchical Rearrangement.</strong>
    <br>
    <strong>Jianyuan Guo*</strong>, Yehui Tang*, Kai Han, Xinghao Chen, Han Wu, Chao Xu, Chang Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2108.13341">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/Hire-Wave-MLP.pytorch">code</a> 
    </p>

    <p>
    <li><strong>CMT: Convolutional Neural Networks Meet Vision Transformers.</strong>
    <br>
    <strong>Jianyuan Guo</strong>, Kai Han, Han Wu, Chang Xu, Yehui Tang, Chunjing Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2107.06263">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/CMT.pytorch">code</a>  
    </p>

    <p>
    <li><strong>An Image Patch is a Wave: Quantum Inspired Vision MLP (WaveMLP).</strong>
    <br>
    Yehui Tang, Kai Han, <strong>Jianyuan Guo</strong>, Chang Xu, Yanxi Li, Chao Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2111.12294">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/Hire-Wave-MLP.pytorch">code</a>
    </p>

    <p>
    <li><strong>Brain-inspired Multilayer Perceptron with Spiking Neurons.</strong>
    <br>
    Wenshuo Li, Hanting Chen, <strong>Jianyuan Guo</strong>, Ziyang Zhang, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2203.14679">paper</a> 
    </p>

    <p>
    <li><strong>Learning efficient vision transformers via fine-grained manifold distillation.</strong>
    <br>
    Zhiwei Hao, <strong>Jianyuan Guo</strong>, Ding Jia, Kai Han, Yehui Tang, Chao Zhang, Han Hu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2022 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/3bd2d73b4e96b0ac5a319be58a96016c-Paper-Conference.pdf">paper</a> 
    </p>
    
    <p>
    <li><strong>Positive-Unlabeled Data Purification in the Wild for Object Detection.</strong>
    <br>
    <strong>Jianyuan Guo</strong>, Kai Han, Han Wu, Chao Zhang, Xinghao Chen, Chunjing Xu, Chang Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2021 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Positive-Unlabeled_Data_Purification_in_the_Wild_for_Object_Detection_CVPR_2021_paper.pdf">paper</a> 
    </p>
    
    <p>
    <li><strong>Distilling object detectors via decoupled features.</strong>
    <br>
    <strong>Jianyuan Guo</strong>, Kai Han, Yunhe Wang, Han Wu, Xinghao Chen, Chunjing Xu, Chang Xu
    <br>
    <em>CVPR</em> 2021 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Guo_Distilling_Object_Detectors_via_Decoupled_Features_CVPR_2021_paper.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/DeFeat.pytorch">code</a>
    </p>
    
    <p>
    <li><strong>Transformer in Transformer.</strong>
    <br>
    Kai Han, An Xiao, Enhua Wu, <strong>Jianyuan Guo</strong>, Chunjing Xu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/huawei-noah/CV-backbones">code</a>
    </p>

    <p>
    <li><strong>Hit-detector: Hierarchical trinity architecture search for object detection.</strong>
    <br>
    <strong>Jianyuan Guo</strong>, Kai Han, Yunhe Wang, Chao Zhang, Zhaohui Yang, Han Wu, Xinghao Chen, Chang Xu
    <br>
    <em>CVPR</em> 2020 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Hit-Detector_Hierarchical_Trinity_Architecture_Search_for_Object_Detection_CVPR_2020_paper.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/HitDet.pytorch">code</a>
    </p>

    <p>
    <li><strong>Ghostnet: More features from cheap operations.</strong>
    <br>
    Kai Han, Yunhe Wang, Qi Tian, <strong>Jianyuan Guo</strong>, Chunjing Xu, Chang Xu
    <br>
    <em>CVPR</em> 2020 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Han_GhostNet_More_Features_From_Cheap_Operations_CVPR_2020_paper.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/huawei-noah/CV-Backbones">code</a>
    </p>

    <p>
    <li><strong>Beyond human parts: Dual part-aligned representations for person re-identification.</strong>
    <br>
    <strong>Jianyuan Guo</strong>, Yuhui Yuan, Lang Huang, Chao Zhang, Jin-Ge Yao, Kai Han
    <br>
    <em>ICCV</em> 2019 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Guo_Beyond_Human_Parts_Dual_Part-Aligned_Representations_for_Person_Re-Identification_ICCV_2019_paper.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/ggjy/P2Net.pytorch">code</a>
    </p>

    <p>
    <li><strong>Attribute-aware attention model for fine-grained representation learning.</strong>
    <br>
    Kai Han*, <strong>Jianyuan Guo*</strong>, Chao Zhang, Mingjian Zhu
    <br>
    <em>ACM MM</em> 2018 | <a style="color: #447ec9" href="https://arxiv.org/pdf/1901.00392.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/iamhankai/attribute-aware-attention">code</a>
    </p>

    <p>
    <li><strong>A Survey on Vision Transformer</strong>
    <br>
    Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, <strong>Jianyuan Guo</strong>, Zhenhua Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang, Dacheng Tao
    <br>
    <em>IEEE T-PAMI</em> 2022 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9716741">paper</a>
    </p>
    </ol>
    </p>

    <p>
    <li><strong>OCNet: Object context for semantic segmentation</strong>
    <br>
    Yuan Yuhui, Lang Huang, <strong>Jianyuan Guo</strong>, Chao Zhang, Xilin Chen, Jingdong Wang
    <br>
    <em>IJCV</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/1809.00916.pdf">paper</a>
    </p>
    </ol>
    </p>

    <p>
    <li><strong>GhostNets on Heterogeneous Devices via Cheap Operations</strong>
    <br>
    Kai Han, Yunhe Wang, Chang Xu, <strong>Jianyuan Guo</strong>, Chunjing Xu, Enhua Wu, Qi Tian
    <br>
    <em>IJCV</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2201.03297.pdf">paper</a>
    </p>
    </ol>
    </p>

  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Student member in the <a href="https://aaai.org/about-aaai/aaai-officers-and-committees/">AAAI Student Committee</a>.</p>
      <p><li> Conference Reviewers of CVPR, ICCV, ECCV, ICLR, ICML, AAAI, NeurIPS, etc.</p>
      <p><li> Journal Reviewers of TPAMI, IJCV, TIP, Pattern Recognition, Neurocomputing, TMLR, etc.</p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Selected Awards</h2>
    <p><li> 2022, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2022">Google PhD Fellowship</a></p>
    <p><li> 2022, Australian Government RTP Scholarship.</p>
    <p><li> 2020, Excellent Graduate, Peking University.</p>
    <p><li> 2018-2019, Award for Scientific Research, Peking University.</p>
    <p><li> 2017-2018, Award for Scientific Research & Benz Scholarship, Peking University.</p>
    <p><li> 2017, Graduate Scholarship, Peking University.</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">
    This website is based on the source code shared by <a href="https://www.wangyunhe.site">Dr. Yunhe Wang</a>. Thanks. 

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
